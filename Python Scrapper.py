# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qwPw5I5myYC_XSCiywYEFCqWhsVhI4Xf
"""

!pip install requests_html

import requests
import pandas as pd
all_websites= pd.read_csv('most_used_url_list.csv')
websites=all_websites['glassdoor_url'].to_list()
out=[]
import time
from requests_html import HTMLSession
for website in websites:
  try:
    session=HTMLSession()
    url=website+'/Reviews/'+'MKTG-Reviews-E352781'+'.htm'
    link=session.get(url)
    block=link.html.find('div.paginationFooter')
    try:
      arr=block[0].text.split(" ")
      temp_1=arr[-2].split(",")
      temp_2=""
      for i in range(len(temp_1)):
        temp_2+=temp_1[i]
      temp=(int(temp_2)//10)+2
    except Exception as e:
      temp=2
    print(arr,arr[-2],url,temp)
    for i in range (1,temp):
      time.sleep(0.01)
      url=website+'/Reviews/'+'MKTG-Reviews-E352781'+'_P'+str(i)+'.htm'
      try:
        link=session.get(url)
        block=link.html.find('div.gdReview')    #represent one block of review
        print(link,url,block)
        for feedback in block:
          temp=[]
          try:
            rating=feedback.find('span.ratingNumber',first=True).text
            temp.append(rating)
          except:
            temp.append('NA')
          try:
            employment_status=feedback.find('span.pt-xsm',first=True).text
            temp.append(employment_status)
          except:
            temp.append('NA')
          try:
            feedback_heading=feedback.find('h2',first=True).text
            temp.append(feedback_heading)
          except:
            temp.append('NA')
          try:
            date=feedback.find('span.authorInfo',first=True).text
            temp.append(date)
          except:
            temp.append('NA')
          try:
            pros=feedback.find('span[data-test="pros"]',first=True).text
            temp.append(pros)
          except:
            temp.append('NA')
          try:
            cons=feedback.find('span[data-test="cons"]',first=True).text
            temp.append(cons)
          except:
            temp.append('NA')
          out.append(temp)
      except Exception as e:
        # print(e)
        continue
  except Exception as e:
    # print(e)
    continue

print(out)

import pandas as pd
scraped_data = pd.DataFrame(out, columns = ["author_rating","employee_status","review_title","review_date_author_job_title","pros_point","cons_point"])
scraped_data = scraped_data.drop_duplicates(subset=None, keep='first', inplace=False)
scraped_data.to_csv('scraped_data_merkle_Reviews.csv')
